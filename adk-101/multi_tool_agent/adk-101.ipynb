{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5e4f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from google.adk.agents import Agent\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.runners import Runner\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "print(\"Libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f5e451e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Keys Set:\n",
      "Google API Key set: Yes\n",
      "OpenAI API Key set: No (REPLACE PLACEHOLDER!)\n",
      "Anthropic API Key set: No (REPLACE PLACEHOLDER!)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Verify Keys (Optional Check) ---\n",
    "print(\"API Keys Set:\")\n",
    "print(f\"Google API Key set: {'Yes' if os.environ.get('GOOGLE_API_KEY') and os.environ['GOOGLE_API_KEY'] != 'YOUR_GOOGLE_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"OpenAI API Key set: {'Yes' if os.environ.get('OPENAI_API_KEY') and os.environ['OPENAI_API_KEY'] != 'YOUR_OPENAI_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "print(f\"Anthropic API Key set: {'Yes' if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'YOUR_ANTHROPIC_API_KEY' else 'No (REPLACE PLACEHOLDER!)'}\")\n",
    "\n",
    "# Configure ADK to use API keys directly (not Vertex AI for this multi-model setup)\n",
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
    "\n",
    "\n",
    "# @markdown **Security Note:** It's best practice to manage API keys securely (e.g., using Colab Secrets or environment variables) rather than hardcoding them directly in the notebook. Replace the placeholder strings above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f6f8012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Environment configured.\n"
     ]
    }
   ],
   "source": [
    "MODEL_GEMINI_2_0_FLASH = \"gemini-2.0-flash-lite\"\n",
    "\n",
    "# Note: Specific model names might change. Refer to LiteLLM or the model provider's documentation.\n",
    "MODEL_GPT_4O = \"openai/gpt-4o\"\n",
    "MODEL_CLAUDE_SONNET = \"anthropic/claude-3-sonnet-20240229\"\n",
    "MODEL_OLLAMA_GEMMA3 = \"ollama/gemma3:latest\"\n",
    "MODEL_OLLAMA_PHI4_MINI = \"ollama/phi4-mini:latest\"\n",
    "MODEL_OLLAMA_GRANITE_3_3 = \"ollama/granite3.3:latest\"\n",
    "\n",
    "print(\"\\nEnvironment configured.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46559806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "# @title Define the get_weather Tool\n",
    "def get_weather(city: str) -> dict:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the weather information.\n",
    "              Includes a 'status' key ('success' or 'error').\n",
    "              If 'success', includes a 'report' key with weather details.\n",
    "              If 'error', includes an 'error_message' key.\n",
    "    \"\"\"\n",
    "    # Best Practice: Log tool execution for easier debugging\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\")\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic input normalization\n",
    "\n",
    "    # Mock weather data for simplicity\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": {\"status\": \"success\", \"report\": \"The weather in New York is sunny with a temperature of 25°C.\"},\n",
    "        \"london\": {\"status\": \"success\", \"report\": \"It's cloudy in London with a temperature of 15°C.\"},\n",
    "        \"tokyo\": {\"status\": \"success\", \"report\": \"Tokyo is experiencing light rain and a temperature of 18°C.\"},\n",
    "    }\n",
    "\n",
    "    # Best Practice: Handle potential errors gracefully within the tool\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return {\"status\": \"error\", \"error_message\": f\"Sorry, I don't have weather information for '{city}'.\"}\n",
    "\n",
    "# Example tool usage (optional self-test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9d6ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Tool: get_weather called for city: New York ---\n",
      "{'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "{'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}\n"
     ]
    }
   ],
   "source": [
    "# @title Define the get_weather Tool\n",
    "def get_weather_english(city: str) -> str:\n",
    "    \"\"\"Retrieves the current weather report for a specified city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city (e.g., \"New York\", \"London\", \"Tokyo\").\n",
    "\n",
    "    Returns:\n",
    "        a simple message in English\n",
    "    \"\"\"\n",
    "    # Best Practice: Log tool execution for easier debugging\n",
    "    print(f\"--- Tool: get_weather called for city: {city} ---\")\n",
    "    city_normalized = city.lower().replace(\" \", \"\") # Basic input normalization\n",
    "\n",
    "    # Mock weather data for simplicity\n",
    "    mock_weather_db = {\n",
    "        \"newyork\": \"The weather in New York is sunny with a temperature of 25°C.\",\n",
    "        \"london\": \"It's cloudy in London with a temperature of 15°C.\",\n",
    "        \"tokyo\": \"Tokyo is experiencing light rain and a temperature of 18°C.\",\n",
    "    }\n",
    "\n",
    "    # Best Practice: Handle potential errors gracefully within the tool\n",
    "    if city_normalized in mock_weather_db:\n",
    "        return mock_weather_db[city_normalized]\n",
    "    else:\n",
    "        return f\"Sorry, I don't have weather information for '{city}'.\"\n",
    "\n",
    "# Example tool usage (optional self-test)\n",
    "print(get_weather(\"New York\"))\n",
    "print(get_weather(\"Paris\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a1ffe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent 'weather_agent_v1' created using model 'gemini-2.0-flash-lite'.\n"
     ]
    }
   ],
   "source": [
    "# @title Define the Weather Agent\n",
    "# Use one of the model constants defined earlier\n",
    "AGENT_MODEL = MODEL_GEMINI_2_0_FLASH # Starting with a powerful Gemini model\n",
    "\n",
    "weather_agent = Agent(\n",
    "    name=\"weather_agent_v1\",\n",
    "    model=AGENT_MODEL, # Specifies the underlying LLM\n",
    "    description=\"Provides weather information for specific cities.\", # Crucial for delegation later\n",
    "    instruction=\"You are a helpful weather assistant. Your primary goal is to provide current weather reports. \"\n",
    "                \"When the user asks for the weather in a specific city, \"\n",
    "                \"you MUST use the 'get_weather' tool to find the information. \"\n",
    "                \"Analyze the tool's response: if the status is 'error', inform the user politely about the error message. \"\n",
    "                \"If the status is 'success', present the weather 'report' clearly and concisely to the user. \"\n",
    "                \"Only use the tool when a city is mentioned for a weather request.\",\n",
    "    tools=[get_weather], # Make the tool available to this agent\n",
    ")\n",
    "\n",
    "print(f\"Agent '{weather_agent.name}' created using model '{AGENT_MODEL}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d8ef1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session created: App='weather_tutorial_app', User='user_1', Session='session_001'\n",
      "Runner created for agent 'weather_agent_v1'.\n"
     ]
    }
   ],
   "source": [
    "# @title Setup Session Service and Runner\n",
    "\n",
    "# --- Session Management ---\n",
    "# Key Concept: SessionService stores conversation history & state.\n",
    "# InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Define constants for identifying the interaction context\n",
    "APP_NAME = \"weather_tutorial_app\"\n",
    "USER_ID = \"user_1\"\n",
    "SESSION_ID = \"session_001\" # Using a fixed ID for simplicity\n",
    "\n",
    "# Create the specific session where the conversation will happen\n",
    "session = session_service.create_session(\n",
    "    app_name=APP_NAME,\n",
    "    user_id=USER_ID,\n",
    "    session_id=SESSION_ID\n",
    ")\n",
    "print(f\"Session created: App='{APP_NAME}', User='{USER_ID}', Session='{SESSION_ID}'\")\n",
    "\n",
    "# --- Runner ---\n",
    "# Key Concept: Runner orchestrates the agent execution loop.\n",
    "runner = Runner(\n",
    "    agent=weather_agent, # The agent we want to run\n",
    "    app_name=APP_NAME,   # Associates runs with our app\n",
    "    session_service=session_service # Uses our session manager\n",
    ")\n",
    "print(f\"Runner created for agent '{runner.agent.name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032bbe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Define Agent Interaction Function\n",
    "import asyncio\n",
    "from google.genai import types # For creating message Content/Parts\n",
    "\n",
    "async def call_agent_async(query: str, runner: Runner, user_id: str, session_id: str):\n",
    "  \"\"\"Sends a query to the agent and prints the final response.\"\"\"\n",
    "  print(f\"\\n>>> User Query: {query}\")\n",
    "\n",
    "  # Prepare the user's message in ADK format\n",
    "  content = types.Content(role='user', parts=[types.Part(text=query)])\n",
    "\n",
    "  final_response_text = \"Agent did not produce a final response.\" # Default\n",
    "\n",
    "  # Key Concept: run_async executes the agent logic and yields Events.\n",
    "  # We iterate through events to find the final answer.\n",
    "  async for event in runner.run_async(user_id=user_id, session_id=session_id, new_message=content):\n",
    "      # You can uncomment the line below to see *all* events during execution\n",
    "      print(f\"  [Event] Author: {event.author}, Type: {type(event).__name__}, Final: {event.is_final_response()}, Content: {event.content}\")\n",
    "\n",
    "      # Key Concept: is_final_response() marks the concluding message for the turn.\n",
    "      if event.is_final_response():\n",
    "          if event.content and event.content.parts:\n",
    "             # Assuming text response in the first part\n",
    "             final_response_text = event.content.parts[0].text\n",
    "          elif event.actions and event.actions.escalate: # Handle potential errors/escalations\n",
    "             final_response_text = f\"Agent escalated: {event.error_message or 'No specific message.'}\"\n",
    "          # Add more checks here if needed (e.g., specific error codes)\n",
    "          break # Stop processing events once the final response is found\n",
    "\n",
    "  print(f\"<<< Agent Response: {final_response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f74430c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> User Query: What is the weather like in London?\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id='adk-67991088-b6f6-4c41-9d6e-48101e218c47', args={'city': 'London'}, name='get_weather'), function_response=None, inline_data=None, text=None)] role='model'\n",
      "--- Tool: get_weather called for city: London ---\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id='adk-67991088-b6f6-4c41-9d6e-48101e218c47', name='get_weather', response={'status': 'success', 'report': \"It's cloudy in London with a temperature of 15°C.\"}), inline_data=None, text=None)] role='user'\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='The weather in London is cloudy with a temperature of 15°C.\\n')] role='model'\n",
      "<<< Agent Response: The weather in London is cloudy with a temperature of 15°C.\n",
      "\n",
      "\n",
      ">>> User Query: How about Paris?\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id='adk-515bd0c0-3cc2-47a1-aaa2-c954028f84a9', args={'city': 'Paris'}, name='get_weather'), function_response=None, inline_data=None, text=None)] role='model'\n",
      "--- Tool: get_weather called for city: Paris ---\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id='adk-515bd0c0-3cc2-47a1-aaa2-c954028f84a9', name='get_weather', response={'status': 'error', 'error_message': \"Sorry, I don't have weather information for 'Paris'.\"}), inline_data=None, text=None)] role='user'\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='I am sorry, I encountered an error when trying to retrieve the weather information for Paris.\\n')] role='model'\n",
      "<<< Agent Response: I am sorry, I encountered an error when trying to retrieve the weather information for Paris.\n",
      "\n",
      "\n",
      ">>> User Query: Tell me the weather in New York\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=FunctionCall(id='adk-75e7ec9d-e5b6-4100-96bc-ed1ef2d71b6c', args={'city': 'New York'}, name='get_weather'), function_response=None, inline_data=None, text=None)] role='model'\n",
      "--- Tool: get_weather called for city: New York ---\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: False, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=FunctionResponse(id='adk-75e7ec9d-e5b6-4100-96bc-ed1ef2d71b6c', name='get_weather', response={'status': 'success', 'report': 'The weather in New York is sunny with a temperature of 25°C.'}), inline_data=None, text=None)] role='user'\n",
      "  [Event] Author: weather_agent_v1, Type: Event, Final: True, Content: parts=[Part(video_metadata=None, thought=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, inline_data=None, text='The weather in New York is sunny with a temperature of 25°C.\\n')] role='model'\n",
      "<<< Agent Response: The weather in New York is sunny with a temperature of 25°C.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title Run the Initial Conversation\n",
    "\n",
    "# We need an async function to await our interaction helper\n",
    "async def run_conversation():\n",
    "    await call_agent_async(\"What is the weather like in London?\", runner, USER_ID, SESSION_ID)\n",
    "    await call_agent_async(\"How about Paris?\", runner, USER_ID, SESSION_ID) # Expecting the tool's error message\n",
    "    await call_agent_async(\"Tell me the weather in New York\", runner, USER_ID, SESSION_ID)\n",
    "\n",
    "# Execute the conversation using await in an async context (like Colab/Jupyter)\n",
    "await run_conversation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "MODEL_LITELLM_GEMINI_2_0_FLASH = \"gemini/gemini-2.0-flash-lite\"\n",
    "load_dotenv()\n",
    "os.environ[\"GEMINI_API_KEY\"] = os.environ.get('GOOGLE_API_KEY')\n",
    "# @title Define and Test Ollama Agent\n",
    "\n",
    "# Make sure 'get_weather' function from Step 1 is defined in your environment.\n",
    "# Make sure 'call_agent_async' is defined from earlier.\n",
    "\n",
    "# --- Agent using Ollama ---\n",
    "weather_agent_ollama = None # Initialize to None\n",
    "runner_ollama = None      # Initialize runner to None\n",
    "\n",
    "model = MODEL_OLLAMA_PHI4_MINI\n",
    "\n",
    "try:\n",
    "    weather_agent_ollama = Agent(\n",
    "        name=\"weather_agent\",\n",
    "        # Key change: Wrap the LiteLLM model identifier\n",
    "        model=LiteLlm(model=model),\n",
    "        description=\"Uses the get_weather_english tool to provides weather information for a specific city.\", \n",
    "        instruction=\"You are a helpful weather assistant. Your primary goal is to provide weather report for a city. \"\n",
    "                \"\\nWhen the user asks for the weather in a city, use the 'get_weather_english' tool to find the weather information.\"\n",
    "                \"\\nAnalyse the response:\"\n",
    "                \"\\n- If the response doesn't have weather details, apologise to the user in a friendly tone. Do not call any further tools!\"\n",
    "                \"\\n- If the response has the weather details, give final response to the user in friendly tone. Do not call any further tools!\\n\",\n",
    "        tools=[get_weather_english], \n",
    "    )\n",
    "    \n",
    "    print(f\"Agent '{weather_agent_ollama.name}' created using model '{model}'.\")\n",
    "\n",
    "    # InMemorySessionService is simple, non-persistent storage for this tutorial.\n",
    "    session_service_ollama = InMemorySessionService() # Create a dedicated service\n",
    "\n",
    "    # Define constants for identifying the interaction context\n",
    "    APP_NAME_OLLAMA = \"weather_tutorial_app_ollama\" # Unique app name for this test\n",
    "    USER_ID_OLLAMA = \"user_1_ollama\"\n",
    "    SESSION_ID_OLLAMA = \"session_001_ollama\" # Using a fixed ID for simplicity\n",
    "\n",
    "    # Create the specific session where the conversation will happen\n",
    "    session_ollama = session_service_ollama.create_session(\n",
    "        app_name=APP_NAME_OLLAMA,\n",
    "        user_id=USER_ID_OLLAMA,\n",
    "        session_id=SESSION_ID_OLLAMA\n",
    "    )\n",
    "    print(f\"Session created: App='{APP_NAME_OLLAMA}', User='{USER_ID_OLLAMA}', Session='{SESSION_ID_OLLAMA}'\")\n",
    "\n",
    "    # Create a runner specific to this agent and its session service\n",
    "    runner_ollama = Runner(\n",
    "        agent=weather_agent_ollama,\n",
    "        app_name=APP_NAME_OLLAMA,       # Use the specific app name\n",
    "        session_service=session_service_ollama # Use the specific session service\n",
    "        )\n",
    "    print(f\"Runner created for agent '{runner_ollama.agent.name}'.\")\n",
    "\n",
    "    # --- Test the Ollama Agent ---\n",
    "    print(\"\\n--- Testing Ollama Agent ---\")\n",
    "    # Ensure call_agent_async uses the correct runner, user_id, session_id\n",
    "    await call_agent_async(query = \"What's the weather in Mumbai?\",\n",
    "                           runner=runner_ollama,\n",
    "                           user_id=USER_ID_OLLAMA,\n",
    "                           session_id=SESSION_ID_OLLAMA)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Could not create or run Ollama agent '{model}'. Check API Key and model name. Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
